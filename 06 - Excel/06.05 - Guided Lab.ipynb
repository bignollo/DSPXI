{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](https://raw.githubusercontent.com/fjvarasc/DSPXI/master/figures/python_logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Guided-Lab-:-Collecting-the-Data\" data-toc-modified-id=\"Guided-Lab-:-Collecting-the-Data-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Guided Lab : Collecting the Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Combining-Data\" data-toc-modified-id=\"Combining-Data-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Combining Data</a></span></li><li><span><a href=\"#Using-Categories\" data-toc-modified-id=\"Using-Categories-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Using Categories</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided Lab : Collecting the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import pandas and numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's import each of our files and combine them into one file. [Panda's concat and append](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html) can do this for us. Then use append in this example.\n",
    "\n",
    "The code snippet below will initialize a blank DataFrame then append all of the individual files into the all_data DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T14:17:09.236132Z",
     "start_time": "2019-03-26T14:16:57.780653Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data = pd.DataFrame()\n",
    "df1 = pd.read_excel('https://github.com/fjvarasc/DSPXI/blob/master/data/sales-mar-2014.xlsx?raw=true')\n",
    "df2 = pd.read_excel('https://github.com/fjvarasc/DSPXI/blob/master/data/sales-feb-2014.xlsx?raw=true')\n",
    "df3 = pd.read_excel('https://github.com/fjvarasc/DSPXI/blob/master/data/sales-jan-2014.xlsx?raw=true')\n",
    "all_data = all_data.append([df1,df2,df3],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T14:17:56.165858Z",
     "start_time": "2019-03-26T14:17:56.111592Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all the data in our all_data DataFrame. but there is one detail, as we saw before the date field  is not recognized as date, it is not critical but the best practice is to convert the date column to a date time object. we can do so by running the below code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T14:25:33.409887Z",
     "start_time": "2019-03-26T14:25:33.345715Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data['date'] = all_data['date'].astype('datetime64[ns]')\n",
    "#all_data['date'] = pd.to_datetime(all_data['date']) this will be valid for the same too\n",
    "all_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use describe to look at it and make sure you data looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T14:25:36.560413Z",
     "start_time": "2019-03-26T14:25:36.371923Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of this data may not make much sense for this data set but for outr purpose we are interested in the count row to make sure the number of data elements makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T14:25:38.383778Z",
     "start_time": "2019-03-26T14:25:38.271302Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all of the data into one DataFrame, we can do any manipulations the DataFrame supports. In this case, the next thing we want to do is read in another file that contains the customer status by account. You can think of this as a company's customer segmentation strategy or some other mechanism for identifying their customers.\n",
    "\n",
    "First, we read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T14:26:04.039462Z",
     "start_time": "2019-03-26T14:26:00.323747Z"
    }
   },
   "outputs": [],
   "source": [
    "status = pd.read_excel(\"https://github.com/fjvarasc/DSPXI/blob/master/data/customer-status.xlsx?raw=true\")\n",
    "status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to merge this data with our concatenated data set of sales. We use panda's merge function and tell it to do a left join which is similar to Excel's vlookup function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T14:26:13.623324Z",
     "start_time": "2019-03-26T14:26:13.427094Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data_st = pd.merge(all_data, status, how='left')\n",
    "all_data_st.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks pretty good but let's look at a specific account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T14:27:15.060134Z",
     "start_time": "2019-03-26T14:27:14.958046Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data_st[all_data_st[\"account number\"]==737550].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This account number was not in our status file, so we have a bunch of NaN's. We can decide how we want to handle this situation. For this specific case, let's label all missing accounts as bronze. Use the fillna function to easily accomplish this on the status column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T14:30:30.361039Z",
     "start_time": "2019-03-26T14:30:30.238119Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data_st['status'].fillna('bronze',inplace=True)\n",
    "all_data_st.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the data just to make sure we're all good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T14:30:42.965758Z",
     "start_time": "2019-03-26T14:30:42.823476Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data_st[all_data_st[\"account number\"]==737550].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all of the data along with the status column filled in. We can do our normal data manipulations using the full suite of pandas capability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the relatively new functions in pandas is support for categorical data. From the pandas, [documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html).\n",
    "\n",
    "\"Categoricals are a pandas data type, which correspond to categorical variables in statistics: a variable, which can take on only a limited, and usually fixed, number of possible values (categories; levels in R). Examples are gender, social class, blood types, country affiliations, observation time or ratings via Likert scales.\"\n",
    "\n",
    "For our purposes, the status field is a good candidate for a category type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we `typecast` it to a category using [astype](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.astype.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T14:34:02.437624Z",
     "start_time": "2019-03-26T14:34:02.413973Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data_st[\"status\"] = all_data_st[\"status\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't immediately appear to change anything yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T14:35:23.494347Z",
     "start_time": "2019-03-26T14:35:23.351280Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data_st.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buy you can see that it is a new data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T14:35:28.686228Z",
     "start_time": "2019-03-26T14:35:28.636939Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data_st.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categories get more interesting when you assign order to the categories. Right now, if we call sort on the column, it will sort alphabetically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T14:35:32.053230Z",
     "start_time": "2019-03-26T14:35:31.900502Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data_st.sort_values(by=[\"status\"]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use set_categories to tell it the order we want to use for this category object. In this case, we use the Olympic medal ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T14:35:37.557120Z",
     "start_time": "2019-03-26T14:35:37.527591Z"
    }
   },
   "outputs": [],
   "source": [
    " all_data_st[\"status\"].cat.set_categories([ \"gold\",\"silver\",\"bronze\"],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can sort it so that gold shows on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T14:35:40.912279Z",
     "start_time": "2019-03-26T14:35:40.784863Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data_st.sort_values(by=[\"status\"]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T14:35:44.088351Z",
     "start_time": "2019-03-26T14:35:44.007646Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data_st[\"status\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, if you want to take a quick look at how your top tier customers are performaing compared to the bottom. Use groupby to give us the average of the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T14:48:37.810617Z",
     "start_time": "2019-03-26T14:48:37.708193Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data_st.groupby([\"status\"])[\"quantity\",\"unit price\",\"ext price\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, you can run multiple aggregation functions on the data to get really useful information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T14:48:45.384478Z",
     "start_time": "2019-03-26T14:48:45.203744Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data_st.groupby([\"status\"])[\"quantity\",\"unit price\",\"ext price\"].agg([np.sum,np.mean, np.std])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what does this tell you? Well, the data is completely random but the first observation is that we sell more units to our bronze customers than gold. Even when you look at the total dollar value associated with bronze vs. gold, it looks backwards.\n",
    "\n",
    "Maybe we should look at how many bronze customers we have and see what is going on.\n",
    "\n",
    "What I plan to do is filter out the unique accounts and see how many gold, silver and bronze customers there are.\n",
    "\n",
    "We've purposely stringing a lot of commands together which is not necessarily best practice but does show how powerful pandas can be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T14:50:08.696493Z",
     "start_time": "2019-03-26T14:50:08.591693Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data_st.drop_duplicates(subset=[\"account number\",\"name\"]).iloc[:,[0,1,7]].groupby([\"status\"])[\"name\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok. This makes a little more sense. We see that we have 9 bronze customers and only 4 gold customers. That is probably why the volumes are so skewed towards our bronze customers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "dspxi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": "5",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
